{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto 2 Ciência dos Dados 2020.1\n",
    "___\n",
    "- Daniel Gurgel Terra\n",
    "- Gabriel Formario\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dada as características biológica dos cogumelos é possível um machine learning determinar se eles são venenosos ou comestíveis ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse arquivo de notebook, construímos as funções que serão utilizadas nos outros notebooks para que fique mais fácil de entender os diferentes processos de classificação. Dessa maneira, os notebooks ficaram mais limpos e mais organizados.\n",
    "Para que isso fosse possível, usamos a biblioteca \"import_ipynb\" (https://pypi.org/project/import-ipynb/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas do scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn é uma biblioteca enorme de machine learnings que utiliza como linguagem o python, é super acessível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O \"train_test_split\", usado como \"separar_treino_teste\", separa grupos de treino e teste\n",
    "from sklearn.model_selection import train_test_split as separar_treino_teste\n",
    "# Árvore de decisões\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "# Regressão Logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Bernoulli Naive Bayes\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Gaussiana Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrói gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "# Constrói tabelas\n",
    "import pandas as pd\n",
    "# Realiza operações matemáticas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados foram extraídos em csv (\"coma separated values\" ou \"valores separados por vírgula\"), são valores como em uma tabela de excel, mas todos separados por vírgula em um arquivo de texto, assim ele é muito leve e muito útil para programação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Json\n",
    "\n",
    "Esse arquivo possui..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lê arquivos no formato \".json\"\n",
    "import json\n",
    "# abrindo o arquivo (não esquecer de por o \"encoding=utf-8\" pois senão não lê letras brasileiras: \"ç\", \"~\", \"^\"...)\n",
    "with open('Renomeador.json', encoding=\"utf-8\") as json_file:\n",
    "    # guarda os valores do dicionário json numa variável\n",
    "    renomeador = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Limpeza dos dados \n",
    "\n",
    "Essa função coleta os novos nomes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Limpeza(data):\n",
    "    # contador, para navegar entre as chaves da tabela a ser limpa\n",
    "    i = 0\n",
    "    # para cada chave e valor do dicionario\n",
    "    for chave,valor in renomeador.items():\n",
    "        # renomeia a coluna pela chave do dicionário\n",
    "        data.rename(columns={data.columns[i]:chave}, inplace=True)\n",
    "        # renomeia os valores na tabela\n",
    "        data[chave].replace(valor, inplace=True)\n",
    "        # vai para a próxima coluna da tabela\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gráfico para cada característica do cogumelo no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset passa pela limpeza para que a função abaixo funcione\n",
    "Limpeza(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grafico_por_caracteristica(intervalo,data):\n",
    "    # coleta o nome das colunas dadas pelo dicionário\n",
    "    colunas = list(renomeador.keys())\n",
    "    # para a quantidade de gráficos desejada\n",
    "    for i in intervalo:\n",
    "        # ajusta o tamanho dos gráficos\n",
    "        plt.figure(figsize=(10,5))\n",
    "        # separa em venenoso e comestível\n",
    "        Venenoso = data[data['Periculosidade']=='venenoso'][colunas[i]].value_counts(True)*100\n",
    "        Comestivel = data[data['Periculosidade']=='comestível'][colunas[i]].value_counts(True)*100\n",
    "        # apresenta o gráfico de comestível para cada característica\n",
    "        plt.bar( np.arange(len(Comestivel)), Comestivel.values.tolist(), width=.25, color=\"g\")\n",
    "        # apresenta o gráfico de venenoso para cada característica, 0.25 unidades adiante\n",
    "        plt.bar( np.arange(len(Venenoso)) + [.25]*len(Venenoso), Venenoso.values.tolist(), width=.25, color=\"r\")\n",
    "        # coloca o nome das características (como são as mesmas para os dois, podia ter sido feito para comestível)\n",
    "        plt.xticks(np.arange(len(Venenoso)) + len(Venenoso)*[0.125],Venenoso.axes[0].tolist())\n",
    "        # nome do eixo vertical, horizontal e título\n",
    "        plt.ylabel(\"Percentual\"); plt.xlabel(\"Características\"); plt.title(colunas[i])\n",
    "        # legenda com as cores para comestível e venenoso\n",
    "        plt.legend(['Comestível','Venenoso'],title=\"Periculosidade\")\n",
    "    # apresenta o gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoder\n",
    "\n",
    "Processo que transforma as variavéis qualitativas em quantitativas de acordo com a respectiva característica\n",
    "\n",
    "Técnica encontrada em : https://www.kaggle.com/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitativo :  ['Livre' 'Ligado']\n"
     ]
    }
   ],
   "source": [
    "print(\"Qualitativo : \", data['Ligação Branqueal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitativo :  [1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "\n",
    "for col in data.columns:\n",
    "    \n",
    "    data[col] = labelencoder.fit_transform(data[col])\n",
    "\n",
    "# o dataset agora possui uma numeração para cada característica\n",
    "print(\"Quantitativo : \", data['Ligação Branqueal'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determinando os dados para o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os dados a serem computados, sem as respostas\n",
    "tabela = data.drop(columns=[\"Periculosidade\"])\n",
    "# coluna-objetivo, a coluna a qual deseja-se prever\n",
    "objetivo = data[\"Periculosidade\"]\n",
    "# tamanho do teste em relação ao total\n",
    "tamanho_teste = 0.8\n",
    "# separando em treino e teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = separar_treino_teste(objetivo, tabela, test_size=tamanho_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Funcao de previsao de modelos utilizadas no Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Previsão(tipo,logistica=False):\n",
    "    \n",
    "    if logistica:\n",
    "        \n",
    "        model = tipo(solver='lbfgs',multi_class='auto',max_iter=1000)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model = tipo()\n",
    "    \n",
    "    model.fit(X_treino,Y_treino);\n",
    "    \n",
    "    model.score(X_teste,Y_teste);\n",
    "    \n",
    "    Y_predict = model.predict(X_teste);\n",
    "    \n",
    "    acertos=0\n",
    "    \n",
    "    for i in range(len(X_teste)):\n",
    "        \n",
    "        if Y_predict[i]==Y_teste.iloc[i]:\n",
    "            \n",
    "            acertos+=1;\n",
    "            \n",
    "    erros = len(X_teste)-acertos\n",
    "    \n",
    "    return round(acertos/len(X_teste)*100,2), round(erros/len(X_teste)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
